## Some AI tests

## Local VLLM/RHAIIS

### [VLLM Basics](https://github.com/alexbarbosa1989/ai-playground/blob/main/ai-basics/vllm-basics.md#vllm-basics)
 - Set local environment
 - Local VLLM usage (GPU and CPU)
 - Basic model chat template interactions via cURL

### [LangChain agent local usage](https://github.com/alexbarbosa1989/ai-playground/blob/main/langgraph-basic-agent/README.md)
- Running a basic agent on the local machine

### [RAIIS agent local usage](https://github.com/alexbarbosa1989/rhaiis-langchain)
- Running a basic agent on the local machine serving the model with RHAIIS

## RHOAI tests

### [Enable GPU in the Openshift cluster and Hardware Profiles](https://github.com/alexbarbosa1989/ai-playground/tree/main/rhoai-tests/hardware-profile)
- Enable GPU in the Openshift Cluster
- Enable Hardware profile
- Create a Hardware profile

### [Configure minio storage in the Openshift cluster](https://github.com/alexbarbosa1989/ai-playground/tree/main/rhoai-tests/minio)
- Create an OpenShift project for Minio
- Deploy minio and test the created resources

### [Serving models with custom vllm-cpu runtime in OpenShift AI](https://github.com/alexbarbosa1989/ai-playground/tree/main/rhoai-tests/rhoai2-cpu-tests)
- Create a custom vLLM custom runtime
- Serving a model using the custom runtime and test it

### [Serving a Model in RHOAI using modelcar](https://github.com/alexbarbosa1989/ai-playground/blob/main/rhoai-tests/serving-modelcar/REDAME.md)
- Create OCI connection
- Serve the model via Single model deployment
- Test the served model

